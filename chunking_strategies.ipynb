{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rich_print\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.chains import create_extraction_chain\n",
    "from typing import Optional, List\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from pydantic import BaseModel\n",
    "from langchain import hub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = ChatOllama(model =\"mistral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG\n",
    "def rag(chunks, collection_name):\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        collection_name=collection_name,\n",
    "        embedding=OllamaEmbeddings(model='nomic-embed-text'),\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | local_llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = chain.invoke(\"What is the use of Text Splitting?\")\n",
    "    rich_print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Character Text Splitting ####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text splitting in LangChain is a cr'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'itical feature that facilitates the'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' division of large texts into small'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'local'</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'er, manageable segments. '</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'local'\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'Text splitting in LangChain is a cr'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'local'\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'itical feature that facilitates the'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'local'\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m' division of large texts into small'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'local'\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'er, manageable segments. '\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text splitting in LangChain is a cr'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'itical feature that facilitates the'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">' division of large texts into small'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'er, manageable segments. '</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'Text splitting in LangChain is a cr'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'itical feature that facilitates the'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m' division of large texts into small'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'er, manageable segments. '\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Character Text Splitting\n",
    "print(\"#### Character Text Splitting ####\")\n",
    "\n",
    "text = \"Text splitting in LangChain is a critical feature that facilitates the division of large texts into smaller, manageable segments. \"\n",
    "\n",
    "# Manual Splitting\n",
    "chunks = []\n",
    "chunk_size = 35 # Characters\n",
    "for i in range(0, len(text), chunk_size):\n",
    "    chunk = text[i:i + chunk_size]\n",
    "    chunks.append(chunk)\n",
    "documents = [Document(page_content=chunk, metadata={\"source\": \"local\"}) for chunk in chunks]\n",
    "rich_print(documents)\n",
    "\n",
    "# Automatic Text Splitting\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 35, chunk_overlap=0, separator='', strip_whitespace=False)\n",
    "documents = text_splitter.create_documents([text])\n",
    "rich_print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Recursive Character Text Splitting ####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text splitting in LangChain is a critical feature that'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'facilitates the division of large texts into smaller, manageable'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'segments.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'This capability is vital for improving comprehension and'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'processing efficiency, especially in tasks that require detailed'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'analysis or extraction of specific contexts.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ChatGPT, developed by OpenAI, represents a leap forward in'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'natural language processing technologies.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"It's a conversational AI model capable of understanding and\"</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'generating human-like text, allowing for dynamic interactions'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'and providing responses that are remarkably coherent and'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'contextually relevant. ChatGPT has been integrated into a'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'multitude of applications, revolutionizing the way we interact'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'with machines and access information.'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'By leveraging LangChain for text splitting, users can'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'efficiently navigate and analyze vast amounts of text data,'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'facilitating a deeper understanding and more insightful'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'conclusions.'</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'Text splitting in LangChain is a critical feature that'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'facilitates the division of large texts into smaller, manageable'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'segments.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'This capability is vital for improving comprehension and'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'processing efficiency, especially in tasks that require detailed'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'analysis or extraction of specific contexts.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'ChatGPT, developed by OpenAI, represents a leap forward in'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'natural language processing technologies.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m\"It\u001b[0m\u001b[32m's a conversational AI model capable of understanding and\"\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'generating human-like text, allowing for dynamic interactions'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'and providing responses that are remarkably coherent and'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'contextually relevant. ChatGPT has been integrated into a'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'multitude of applications, revolutionizing the way we interact'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'with machines and access information.'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'By leveraging LangChain for text splitting, users can'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'efficiently navigate and analyze vast amounts of text data,'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'facilitating a deeper understanding and more insightful'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'conclusions.'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Recursive Character Text Splitting\n",
    "print(\"#### Recursive Character Text Splitting ####\")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "with open('E:\\git\\AI-Algorithm-Journey\\chunking_text.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 65, chunk_overlap=0) # [\"\\n\\n\", \"\\n\", \" \", \"\"] 65,450\n",
    "rich_print(text_splitter.create_documents([text])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Document Specific Splitting ####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'# Fun in California\\n\\n## Driving'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Try driving on the 1 down to San Diego'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'### Food'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Make sure to eat a burrito while you're\"</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'there'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'## Hiking\\n\\nGo to Yosemite'</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'# Fun in California\\n\\n## Driving'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'Try driving on the 1 down to San Diego'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'### Food'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m\"Make\u001b[0m\u001b[32m sure to eat a burrito while you're\"\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'there'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'## Hiking\\n\\nGo to Yosemite'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Document Specific Splitting\n",
    "print(\"#### Document Specific Splitting ####\")\n",
    "\n",
    "# Document Specific Splitting - Markdown\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "splitter = MarkdownTextSplitter(chunk_size = 40, chunk_overlap=0)\n",
    "markdown_text = \"\"\"\n",
    "# Fun in California\n",
    "\n",
    "## Driving\n",
    "\n",
    "Try driving on the 1 down to San Diego\n",
    "\n",
    "### Food\n",
    "\n",
    "Make sure to eat a burrito while you're there\n",
    "\n",
    "## Hiking\n",
    "\n",
    "Go to Yosemite\n",
    "\"\"\"\n",
    "rich_print(splitter.create_documents([markdown_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'class Person:\\n  def __init__(self, name, age):\\n    self.name = name\\n    self.age = age'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'p1 = Person(\"John\", 36)\\n\\nfor i in range(10):\\n    print (i)'</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'class Person:\\n  def __init__\u001b[0m\u001b[32m(\u001b[0m\u001b[32mself, name, age\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n    self.name = name\\n    self.age = age'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'p1 = Person\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\"John\", 36\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nfor i in range\u001b[0m\u001b[32m(\u001b[0m\u001b[32m10\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n    print \u001b[0m\u001b[32m(\u001b[0m\u001b[32mi\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Document Specific Splitting - Python\n",
    "from langchain.text_splitter import PythonCodeTextSplitter\n",
    "python_text = \"\"\"\n",
    "class Person:\n",
    "  def __init__(self, name, age):\n",
    "    self.name = name\n",
    "    self.age = age\n",
    "\n",
    "p1 = Person(\"John\", 36)\n",
    "\n",
    "for i in range(10):\n",
    "    print (i)\n",
    "\"\"\"\n",
    "python_splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "rich_print(python_splitter.create_documents([python_text]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'// Function is called, the return value will end up in x'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'let x = myFunction(4, 3);'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'function myFunction(a, b) {'</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'// Function returns the product of a and b\\n  return a * b;\\n}'</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'// Function is called, the return value will end up in x'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'let x = myFunction\u001b[0m\u001b[32m(\u001b[0m\u001b[32m4, 3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m;'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'function myFunction\u001b[0m\u001b[32m(\u001b[0m\u001b[32ma, b\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpage_content\u001b[0m=\u001b[32m'// Function returns the product of a and b\\n  return a * b;\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Document Specific Splitting - Javascript\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "javascript_text = \"\"\"\n",
    "// Function is called, the return value will end up in x\n",
    "let x = myFunction(4, 3);\n",
    "\n",
    "function myFunction(a, b) {\n",
    "// Function returns the product of a and b\n",
    "  return a * b;\n",
    "}\n",
    "\"\"\"\n",
    "js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS, chunk_size=65, chunk_overlap=0\n",
    ")\n",
    "rich_print(js_splitter.create_documents([javascript_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openapi_key = os.environ.get('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Semantic Chunking ####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Text splitting in LangChain is a critical feature that facilitates the division of large </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">texts into smaller, manageable segments. This capability is vital for improving comprehension and processing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency, especially in tasks that require detailed analysis or extraction of specific contexts.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"ChatGPT, developed by OpenAI, represents a leap forward in natural language processing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">technologies. It's a conversational AI model capable of understanding and generating human-like text, allowing for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dynamic interactions and providing responses that are remarkably coherent and contextually relevant. ChatGPT has </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">been integrated into a multitude of applications, revolutionizing the way we interact with machines and access </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information. By leveraging LangChain for text splitting, users can efficiently navigate and analyze vast amounts of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">text data, facilitating a deeper understanding and more insightful conclusions.\"</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Text splitting in LangChain is a critical feature that facilitates the division of large \u001b[0m\n",
       "\u001b[32mtexts into smaller, manageable segments. This capability is vital for improving comprehension and processing \u001b[0m\n",
       "\u001b[32mefficiency, especially in tasks that require detailed analysis or extraction of specific contexts.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m\"ChatGPT\u001b[0m\u001b[32m, developed by OpenAI, represents a leap forward in natural language processing \u001b[0m\n",
       "\u001b[32mtechnologies. It's a conversational AI model capable of understanding and generating human-like text, allowing for \u001b[0m\n",
       "\u001b[32mdynamic interactions and providing responses that are remarkably coherent and contextually relevant. ChatGPT has \u001b[0m\n",
       "\u001b[32mbeen integrated into a multitude of applications, revolutionizing the way we interact with machines and access \u001b[0m\n",
       "\u001b[32minformation. By leveraging LangChain for text splitting, users can efficiently navigate and analyze vast amounts of\u001b[0m\n",
       "\u001b[32mtext data, facilitating a deeper understanding and more insightful conclusions.\"\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Semantic Chunking\n",
    "print(\"#### Semantic Chunking ####\")\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "with open('E:\\git\\AI-Algorithm-Journey\\chunking_text.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read() \n",
    "\n",
    "# Percentile - all differences between sentences are calculated, and then any difference greater than the X percentile is split\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings(api_key=openapi_key))\n",
    "text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\" # \"standard_deviation\", \"interquartile\"\n",
    ")\n",
    "documents = text_splitter.create_documents([text])\n",
    "rich_print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Proposition-Based Chunking ####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johns\\anaconda3\\envs\\chunking\\Lib\\site-packages\\langsmith\\client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 0\n",
      "Done with 1\n",
      "Done with 2\n",
      "Done with 3\n"
     ]
    }
   ],
   "source": [
    "# 5. Agentic Chunking\n",
    "print(\"#### Proposition-Based Chunking ####\")\n",
    "\n",
    "\n",
    "class Sentences(BaseModel):\n",
    "    sentences: List[str]\n",
    "\n",
    "text = \"Text splitting in LangChain is a critical feature that facilitates the division of large texts into smaller, manageable segments. \"\n",
    "with open('E:\\git\\AI-Algorithm-Journey\\chunking_text.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read() \n",
    "\n",
    "\n",
    "# https://arxiv.org/pdf/2312.06648.pdf\n",
    "obj = hub.pull(\"wfh/proposal-indexing\")\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo').with_structured_output(Sentences)\n",
    "runnable = obj | llm\n",
    "\n",
    "\n",
    "\n",
    "# Extraction\n",
    "# extraction_chain = create_extraction_chain_pydantic(pydantic_schema=Sentences, llm=llm)\n",
    "def get_propositions(text):\n",
    "    # Create an LLM with structured output based on the Sentences schema\n",
    "    # structured_llm = runnable.with_structured_output(Sentences)\n",
    "\n",
    "    # Invoke the LLM with the input text and get the structured output\n",
    "    runnable_output = runnable.invoke({\n",
    "        \"input\": text\n",
    "    })\n",
    "\n",
    "    # Extract sentences from the structured output\n",
    "    propositions = runnable_output.sentences\n",
    "\n",
    "    return propositions\n",
    "paragraphs = text.split(\"\\n\")\n",
    "text_propositions = []\n",
    "for i, para in enumerate(paragraphs[:5]):\n",
    "    propositions = get_propositions(para)\n",
    "    text_propositions.extend(propositions)\n",
    "    print (f\"Done with {i}\")\n",
    "\n",
    "\n",
    "rich_print (f\"You have {len(text_propositions)} propositions\")\n",
    "rich_print(text_propositions[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Agentic Chunking ####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johns\\AppData\\Local\\Temp\\ipykernel_22360\\3972065590.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from agentic_chunker import AgenticChunker\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'Text splitting in LangChain is a critical feature.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'Text splitting in LangChain is a critical feature.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks, creating a new one\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks, creating a new one\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span>112bf<span style=\"font-weight: bold\">)</span>: Text Splitting\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0m112bf\u001b[1m)\u001b[0m: Text Splitting\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'Text splitting facilitates the division of large texts into smaller, manageable segments.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'Text splitting facilitates the division of large texts into smaller, manageable segments.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\git\\AI-Algorithm-Journey\\agentic_chunker.py:296: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` thatis available on ChatModels capable of tool calling.You can read more about the method here: <https://python.langchain.com/docs/modules/model_io/chat/structured_output/>. Please follow our extraction use case documentation for more guidelineson how to do information extraction with LLMs.<https://python.langchain.com/docs/use_cases/extraction/>. If you notice other issues, please provide feedback here:<https://github.com/langchain-ai/langchain/discussions/18154>\n",
      "  extraction_chain = create_extraction_chain_pydantic(pydantic_schema=ChunkID, llm=self.llm)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks found\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks found\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span>a2fb6<span style=\"font-weight: bold\">)</span>: Text Splitting for Information Management\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0ma2fb6\u001b[1m)\u001b[0m: Text Splitting for Information Management\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'This capability is vital for improving comprehension and processing efficiency.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'This capability is vital for improving comprehension and processing efficiency.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks found\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks found\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span>76b96<span style=\"font-weight: bold\">)</span>: Skills &amp; Efficiency\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0m76b96\u001b[1m)\u001b[0m: Skills & Efficiency\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'This is especially important in tasks that require detailed analysis or extraction of specific contexts.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'This is especially important in tasks that require detailed analysis or extraction of specific contexts.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks found\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks found\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span>9e66d<span style=\"font-weight: bold\">)</span>: Attention to Detail\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0m9e66d\u001b[1m)\u001b[0m: Attention to Detail\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'The sky is blue and the sun is shining brightly.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'The sky is blue and the sun is shining brightly.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks found\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks found\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span>eb61c<span style=\"font-weight: bold\">)</span>: Weather Conditions\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0meb61c\u001b[1m)\u001b[0m: Weather Conditions\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatGPT represents a leap forward in natural language processing technologies.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'ChatGPT represents a leap forward in natural language processing technologies.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks found\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks found\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span>a7853<span style=\"font-weight: bold\">)</span>: Technology &amp; Innovation\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0ma7853\u001b[1m)\u001b[0m: Technology & Innovation\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatGPT was developed by OpenAI.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'ChatGPT was developed by OpenAI.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks found\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks found\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span>31c4d<span style=\"font-weight: bold\">)</span>: Technology &amp; Innovation\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0m31c4d\u001b[1m)\u001b[0m: Technology & Innovation\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'It'</span>s a conversational AI model capable of understanding and generating human-like text.'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'It'\u001b[0ms a conversational AI model capable of understanding and generating human-like text.'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks found\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks found\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span>795df<span style=\"font-weight: bold\">)</span>: Artificial Intelligence\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0m795df\u001b[1m)\u001b[0m: Artificial Intelligence\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'It allows for dynamic interactions and provides responses that are remarkably coherent and contextually </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relevant.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'It allows for dynamic interactions and provides responses that are remarkably coherent and contextually \u001b[0m\n",
       "\u001b[32mrelevant.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks found\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks found\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span>b3b1c<span style=\"font-weight: bold\">)</span>: Artificial Intelligence Systems\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0mb3b1c\u001b[1m)\u001b[0m: Artificial Intelligence Systems\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'ChatGPT has been integrated into a multitude of applications.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'ChatGPT has been integrated into a multitude of applications.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks found\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks found\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span>55fde<span style=\"font-weight: bold\">)</span>: Applications of ChatGPT\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0m55fde\u001b[1m)\u001b[0m: Applications of ChatGPT\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Adding: <span style=\"color: #008000; text-decoration-color: #008000\">'It has revolutionized the way we interact with machines and access information.'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Adding: \u001b[32m'It has revolutionized the way we interact with machines and access information.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No chunks found\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No chunks found\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Created new chunk <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46e28</span><span style=\"font-weight: bold\">)</span>: Technology &amp; Daily Life\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Created new chunk \u001b[1m(\u001b[0m\u001b[1;36m46e28\u001b[0m\u001b[1m)\u001b[0m: Technology & Daily Life\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "You have <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> chunks\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "You have \u001b[1;36m11\u001b[0m chunks\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: 112bf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: 112bf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk discusses the importance of text splitting in LangChain.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk discusses the importance of text splitting in LangChain.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -Text splitting in LangChain is a critical feature.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -Text splitting in LangChain is a critical feature.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: a2fb6\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: a2fb6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk discusses the benefits and process of text splitting for managing large amounts of information.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk discusses the benefits and process of text splitting for managing large amounts of information.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -Text splitting facilitates the division of large texts into smaller, manageable segments.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -Text splitting facilitates the division of large texts into smaller, manageable segments.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: 76b96\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: 76b96\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk discusses the importance of a specific capability for enhancing understanding and efficiency.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk discusses the importance of a specific capability for enhancing understanding and efficiency.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -This capability is vital for improving comprehension and processing efficiency.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -This capability is vital for improving comprehension and processing efficiency.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: 9e66d\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: 9e66d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk discusses the importance of paying attention to details in tasks that involve detailed analysis\n",
       "or extraction of specific contexts.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk discusses the importance of paying attention to details in tasks that involve detailed analysis\n",
       "or extraction of specific contexts.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -This is especially important in tasks that require detailed analysis or extraction of specific contexts.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -This is especially important in tasks that require detailed analysis or extraction of specific contexts.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: eb61c\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: eb61c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk describes the current weather conditions.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk describes the current weather conditions.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -The sky is blue and the sun is shining brightly.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -The sky is blue and the sun is shining brightly.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: a7853\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: a7853\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk discusses advancements in natural language processing technologies.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk discusses advancements in natural language processing technologies.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -ChatGPT represents a leap forward in natural language processing technologies.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -ChatGPT represents a leap forward in natural language processing technologies.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: 31c4d\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: 31c4d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk provides information about the development of ChatGPT by OpenAI.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk provides information about the development of ChatGPT by OpenAI.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -ChatGPT was developed by OpenAI.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -ChatGPT was developed by OpenAI.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m7\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: 795df\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: 795df\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk discusses the capabilities of a conversational AI model in understanding and generating \n",
       "human-like text.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk discusses the capabilities of a conversational AI model in understanding and generating \n",
       "human-like text.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -It's a conversational AI model capable of understanding and generating human-like text.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -It's a conversational AI model capable of understanding and generating human-like text.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m8\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: b3b1c\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: b3b1c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk discusses the capabilities of a particular technology or system in providing coherent and \n",
       "contextually relevant responses during dynamic interactions.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk discusses the capabilities of a particular technology or system in providing coherent and \n",
       "contextually relevant responses during dynamic interactions.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -It allows for dynamic interactions and provides responses that are remarkably coherent and contextually \n",
       "relevant.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -It allows for dynamic interactions and provides responses that are remarkably coherent and contextually \n",
       "relevant.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: 55fde\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: 55fde\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk discusses the various applications where ChatGPT has been integrated.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk discusses the various applications where ChatGPT has been integrated.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -ChatGPT has been integrated into a multitude of applications.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -ChatGPT has been integrated into a multitude of applications.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk #\u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Chunk ID: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">46e28</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Chunk ID: \u001b[1;36m46e28\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Summary: This chunk discusses the impact of technology on our daily lives.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Summary: This chunk discusses the impact of technology on our daily lives.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Propositions:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Propositions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    -It has revolutionized the way we interact with machines and access information.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    -It has revolutionized the way we interact with machines and access information.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3;35mNone\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Text splitting in LangChain is a critical feature.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'Text splitting facilitates the division of large texts into smaller, manageable segments.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'This capability is vital for improving comprehension and processing efficiency.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'This is especially important in tasks that require detailed analysis or extraction of specific contexts.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'The sky is blue and the sun is shining brightly.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ChatGPT represents a leap forward in natural language processing technologies.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ChatGPT was developed by OpenAI.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"It's a conversational AI model capable of understanding and generating human-like text.\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'It allows for dynamic interactions and provides responses that are remarkably coherent and contextually </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relevant.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ChatGPT has been integrated into a multitude of applications.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'It has revolutionized the way we interact with machines and access information.'</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[32m'Text splitting in LangChain is a critical feature.'\u001b[0m,\n",
       "    \u001b[32m'Text splitting facilitates the division of large texts into smaller, manageable segments.'\u001b[0m,\n",
       "    \u001b[32m'This capability is vital for improving comprehension and processing efficiency.'\u001b[0m,\n",
       "    \u001b[32m'This is especially important in tasks that require detailed analysis or extraction of specific contexts.'\u001b[0m,\n",
       "    \u001b[32m'The sky is blue and the sun is shining brightly.'\u001b[0m,\n",
       "    \u001b[32m'ChatGPT represents a leap forward in natural language processing technologies.'\u001b[0m,\n",
       "    \u001b[32m'ChatGPT was developed by OpenAI.'\u001b[0m,\n",
       "    \u001b[32m\"It's a conversational AI model capable of understanding and generating human-like text.\"\u001b[0m,\n",
       "    \u001b[32m'It allows for dynamic interactions and provides responses that are remarkably coherent and contextually \u001b[0m\n",
       "\u001b[32mrelevant.'\u001b[0m,\n",
       "    \u001b[32m'ChatGPT has been integrated into a multitude of applications.'\u001b[0m,\n",
       "    \u001b[32m'It has revolutionized the way we interact with machines and access information.'\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> The use of Text Splitting, as mentioned in the provided context, facilitates the division of large texts into \n",
       "smaller, manageable segments. This capability is crucial for improving comprehension and processing efficiency, \n",
       "particularly within a conversational AI model like LangChain.\n",
       "</pre>\n"
      ],
      "text/plain": [
       " The use of Text Splitting, as mentioned in the provided context, facilitates the division of large texts into \n",
       "smaller, manageable segments. This capability is crucial for improving comprehension and processing efficiency, \n",
       "particularly within a conversational AI model like LangChain.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"#### Agentic Chunking ####\")\n",
    "\n",
    "from agentic_chunker import AgenticChunker\n",
    "ac = AgenticChunker()\n",
    "ac.add_propositions(text_propositions)\n",
    "rich_print(ac.pretty_print_chunks())\n",
    "chunks = ac.get_chunks(get_type='list_of_strings')\n",
    "rich_print(chunks)\n",
    "documents = [Document(page_content=chunk, metadata={\"source\": \"local\"}) for chunk in chunks]\n",
    "rag(documents, \"agentic-chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chunking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
